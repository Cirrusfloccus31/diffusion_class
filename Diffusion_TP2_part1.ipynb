{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3QUXwLwtDKG"
      },
      "source": [
        "# INSA, GMM Image\n",
        "## Practical sessions: Introduction to Diffusion\n",
        "\n",
        "Welcome in this second practical session on diffusion models.  \n",
        "In the previous session we saw how to train a diffusion model on a toy 2d dataset.  \n",
        "Today we will continue a little bit on a similar dataset to work and see if we manage to learn a class conditionned diffusion model.  \n",
        "After that we will work with pretrained models for image generation and try try several things to improve the quality of the generated images.  \n",
        "Finally we will play a bit with a stable diffusion model to generate images from text, do some inpainting or image conditioning.  \n",
        "Finally we will use an inversion mechanism to carefully edit images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's start by doin our noise conditionned diffusion model.  \n",
        "To illustrate the concept of class conditionned diffusion, we will work with a two class dataset, called two moons.  \n",
        "You probably know it from the sklearn library.  It is a simple dataset with two classes and two features.  \n",
        "Let's load it and plot it.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from sklearn.datasets import make_moons\n",
        "\n",
        "def get_moons_dataset(n_samples=1000, noise=0.1, random_state=42):\n",
        "    x_0, y = make_moons(n_samples=n_samples, noise=noise, random_state=random_state)\n",
        "    x_0 = torch.FloatTensor(x_0)\n",
        "    y = torch.LongTensor(y)\n",
        "    \n",
        "    return x_0, y\n",
        "\n",
        "x_0, y = get_moons_dataset()\n",
        "print(f\"Features shape: {x_0.shape}\") \n",
        "print(f\"Labels shape: {y.shape}\")   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(x_0[:,0],x_0[:,1],c=y)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zovEk0LBtDKI"
      },
      "source": [
        "We will use this dataset to illustrate the concept of class conditionned diffusion.  \n",
        "This data will be our initial distribution, the one we want to sample from and the class will be our condition.  \n",
        "Like in the previous session, we don't know how to sample from this distribution.  We will use a noise schedule to gradually add noise to the data until we reach a Gaussian distribution for which we know how to sample.  Then we will use the reverse process to sample from the initial distribution.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvG33EWkXqIk"
      },
      "source": [
        "### Noise Schedule\n",
        "Let's begin by defining the noise schedule.  \n",
        "The noise schedule is a function that defines the amount of noise to add at each timestep.  \n",
        "We will use a linear schedule for this example.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 560
        },
        "id": "TqfYBhI0XWAM",
        "outputId": "29f58c56-357d-4377-e7de-01ad839a0cac"
      },
      "outputs": [],
      "source": [
        "T=200\n",
        "alpha_min=0.0001\n",
        "alpha_max=0.05\n",
        "alphas = torch.linspace(alpha_min, alpha_max, T)\n",
        "alphas = 1. - alphas\n",
        "alpha_bar = torch.cumprod(alphas, dim=0)\n",
        "plt.figure(figsize=[6, 6])\n",
        "plt.plot(torch.arange(T), alpha_bar)\n",
        "plt.xlabel('Timestep')\n",
        "plt.ylim(0,1.05)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKcuJH7WtDKI"
      },
      "source": [
        "### Forward Pass\n",
        "The forward pass is the process of adding noise to the data at each timestep.  \n",
        "We will use the noise schedule to define the amount of noise to add at each timestep.  \n",
        "We saw in class that the forward step can be written as:\n",
        "$$x_t = \\sqrt{\\alpha_t}x_{t-1} + \\sqrt{1-\\alpha_t}\\epsilon_t$$\n",
        "where $\\alpha_t$ is the amount of noise to add at timestep $t$ and $\\epsilon_t$ is a noise sample.  \n",
        "Here is the function to perform the forward pass.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYg1c48PoRSw"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "\n",
        "def forward_step(x_t_minus_1:torch.Tensor, alphas:torch.Tensor, t:int, eps:torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Takes the previous step, the alphas and the timestep and returns the next step\n",
        "    args:\n",
        "        x_t_minus_1: the previous step\n",
        "        alphas: the alphas of the noise schedule\n",
        "        t: the timestep\n",
        "        eps: the noise sample\n",
        "    returns:\n",
        "        x_t: the next step\n",
        "    \"\"\"\n",
        "    return alphas[t].sqrt()*x_t_minus_1 + (1-alphas[t]).sqrt()*eps\n",
        "\n",
        "def forward_pass(x_0:torch.Tensor, alphas:torch.Tensor, T:int=200) -> List[torch.Tensor]:\n",
        "    \"\"\"\n",
        "    Takes the initial data, the alphas and the number of timesteps and returns the list of forward steps\n",
        "    args:\n",
        "        x_0: the initial data\n",
        "        alphas: the alphas of the noise schedule\n",
        "        T: the number of timesteps\n",
        "    returns:\n",
        "        x_series: a list of the forward steps\n",
        "    \"\"\"\n",
        "    x_series = [x_0]\n",
        "    for t in range(T):\n",
        "        eps = torch.randn_like(x_0)\n",
        "        x_series.append(forward_step(x_series[-1], alphas, t, eps))\n",
        "    return x_series\n",
        "\n",
        "x_series = forward_pass(x_0, alphas, T)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTa3E4EGtDKJ"
      },
      "source": [
        "Now plot the different steps of the forward pass for t = [0, 12, 25, 50, 75, 100, 125, 150, 175, 200]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "4nYrBUNttDKJ",
        "outputId": "b48aada8-b2d4-48dc-9cc7-c74555d24643"
      },
      "outputs": [],
      "source": [
        "figure = plt.figure(figsize=(20, 10))\n",
        "for i, t in enumerate([0, 12, 25, 50, 75, 100, 125, 150, 175, 200]):\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuVJDPwjtDKJ"
      },
      "source": [
        "You should observe that the data becomes more and more noisy as the timestep increases.  \n",
        "The following code animates the forward pass and allows you to see the data evolve over time.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lalR9En6tDKJ",
        "outputId": "8b4b4a6d-dafa-4e8b-a7bc-a713820d1212"
      },
      "outputs": [],
      "source": [
        "from matplotlib.animation import FuncAnimation\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import HTML\n",
        "from functools import partial\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6, 6))\n",
        "\n",
        "def animate(i:int, series:List[torch.Tensor], labels:torch.Tensor):\n",
        "    ax.clear()\n",
        "    data = series[i]\n",
        "    ax.scatter(data[:, 0], data[:, 1], s=15, alpha=0.5, c=y)\n",
        "    ax.set_axis_off()\n",
        "\n",
        "animate_forward = partial(animate, series=x_series, labels=y)\n",
        "\n",
        "anim = FuncAnimation(fig, animate_forward, frames=len(x_series),\n",
        "                    interval=250)  # 500ms between frames\n",
        "\n",
        "HTML(anim.to_jshtml())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P80puz4EtDKK"
      },
      "source": [
        "For training, we would like to have diversity in the training batches, meaning different samples with different timesteps.  \n",
        "We saw in class that it is to directly noise the data for a given timestep without having to go through the forward pass for all the timesteps.  \n",
        "$$x_t = \\sqrt{\\bar{\\alpha_t}}x_{t-1} + \\sqrt{1-\\bar{\\alpha_t}}\\epsilon_t$$\n",
        "The following function to sample the data for a given timestep."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "ood3rtnetDKK",
        "outputId": "ef521cd0-5e2f-4a7d-a484-5380844b3bf3"
      },
      "outputs": [],
      "source": [
        "def sample_x_t(x_0:torch.Tensor, t:int, alpha_bar:torch.Tensor, eps:torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Takes the initial data, the alphas and the number of timesteps and returns a noisy version of the data for a given timestep\n",
        "    args:\n",
        "        x_0: the initial data\n",
        "        alphas: the alphas of the noise schedule\n",
        "        T: the number of timesteps\n",
        "    returns:\n",
        "        x_t: a noisy version of the data for a given timestep\n",
        "    \"\"\"\n",
        "    return alpha_bar[t, None].sqrt()*x_0 + (1.-alpha_bar[t, None]).sqrt()*eps\n",
        "\n",
        "\n",
        "figure = plt.figure(figsize=(20, 4))\n",
        "for i, t in enumerate([0, 6, 12, 25, 50]):\n",
        "    dataset, time_step = x_series[t], t\n",
        "    figure.add_subplot(1, 5, i+1)\n",
        "    plt.title(time_step)\n",
        "    plt.axis(\"off\")\n",
        "    eps = torch.randn_like(x_0)\n",
        "    x_t = sample_x_t(x_0, t, alpha_bar, eps)\n",
        "    plt.scatter(x_t[:,0], x_t[:,1],s=15,alpha=0.5, c=y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEX8iUOutDKK"
      },
      "source": [
        "## Training\n",
        "We will now train a denoising model to learn the reverse process.  \n",
        "First, we need to create a dataset with our data.  \n",
        "### Dataset\n",
        "We now define a torch dataset to load our data.  We then split the data into a train and test set and create dataloaders for each.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmNBG87EtDKK"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "\n",
        "class TwoMoonsDataset(Dataset):\n",
        "    def __init__(self, n_samples=1000, noise=0.1, random_state=42):\n",
        "        x_0, y = make_moons(n_samples=n_samples, noise=noise, random_state=random_state)\n",
        "        self.x_0 = torch.FloatTensor(x_0)\n",
        "        self.y = torch.LongTensor(y)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x_0)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.x_0[idx].float(), self.y[idx]\n",
        "\n",
        "dataset = TwoMoonsDataset()\n",
        "\n",
        "# Train/Test Split\n",
        "train_size = int(0.9 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "batch_size = 128\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtPGITp5gT50"
      },
      "source": [
        "### Model:\n",
        "Now that the dataset and dataloaders are created, we can define the model.  \n",
        "We will use a simple MLP with 5 layers of 64 neurons each and a final layer to output the predicted noise.\n",
        "We will use the GELU activation function between each layer.  \n",
        "Remember that the output of the model will be the predicted noise which has the same dimension as the input.\n",
        "Complete the following class to define the model.  \n",
        "Since we will be training the model on the data for different timesteps, we will need to pass the timestep as an additional input to the model.  \n",
        "We will do this by concatenating the timestep to the input data.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SqG9nL4MtDKK"
      },
      "outputs": [],
      "source": [
        "class Denoisier(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layers = torch.nn.Sequential(\n",
        "            torch.nn.Linear(3, 64),\n",
        "            torch.nn.GELU(),\n",
        "            torch.nn.Linear(64, 64),\n",
        "            torch.nn.GELU(),\n",
        "            torch.nn.Linear(64, 64),\n",
        "            torch.nn.GELU(),\n",
        "            torch.nn.Linear(64, 64),\n",
        "            torch.nn.GELU(),\n",
        "            torch.nn.Linear(64, 2),\n",
        "        )\n",
        "    def forward(self, x, t):\n",
        "        x = torch.cat((x, t.reshape(-1, 1)), dim=1)\n",
        "        return self.layers(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdZz4uzugmQ6"
      },
      "source": [
        "### Training loop:\n",
        "At this point, we have all the components to train the model.  \n",
        "The training loop of a denoising model is actually quite simple.  \n",
        "Look at the training algorithm from the paper and implement the training loop.  \n",
        "![training_loop](images/training.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_bh_QyutDKK"
      },
      "outputs": [],
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "def train(model, train_dataloader, optimizer, alpha_bar, epochs=50, device='cpu'):\n",
        "    progress_bar = tqdm(range(epochs), desc=\"Training\")\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for x, y in train_dataloader:\n",
        "            x = x.to(device)\n",
        "            eps = torch.randn_like(x)\n",
        "            t = torch.randint(T, (x.shape[0],), device=device)\n",
        "            x_t = sample_x_t(x, t, alpha_bar.to(device), eps)\n",
        "            eps_pred = model(x_t, t)\n",
        "            loss = torch.nn.functional.mse_loss(eps_pred, eps)\n",
        "            total_loss += loss.item()*x.shape[0]\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        progress_bar.set_postfix({\"epoch\": epoch, \"loss\": total_loss/x.shape[0]})\n",
        "        progress_bar.update()\n",
        "    progress_bar.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gyOSMWptDKK"
      },
      "source": [
        "### Training:\n",
        "Now instantiate the model and optimizer (Adam with a learning rate of 1e-3) and train the model for 3000 epochs.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "ff0ec0705d0b4b899c27405e49777904",
            "e28e0b941950447a98da71efeff9f1c2",
            "8a97e77fb5cd4b4aae8ead106ea700c6",
            "2b977a780d6b47a691699be9254c576c",
            "44ff2d36b1ac4dd2b699d91df263c925",
            "5df7af6dc686422bbde6a1366d37b4f1",
            "043d01bcd99641fda43e813ba2efe7e8",
            "fa5f340489b94fb8acbdbf7ef874e571",
            "971de86e5d6f4f30827ea8e66ab3dcf2",
            "fef32e50cebd439995b6dd3213e62da4",
            "9306690fc9a6405b85be4fc0b86b85db"
          ]
        },
        "id": "r2EveO0otDKK",
        "outputId": "221675bf-eade-45ca-a133-ef97c630d079"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = Denoisier().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "train(model, train_loader, optimizer, alpha_bar, epochs=3000, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4jRNgL5tDKK"
      },
      "source": [
        "### Sampling:\n",
        "Here is the moment of truth!\n",
        "We will now sample from the model and see if we did manage to learn the reverse process.  \n",
        "Remember that the sampling algorithm is the following:  \n",
        "![sampling_loop](images/sampling.png)  \n",
        "Use this function to sample 1000 points and plot them.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "id": "J_xLK18MhMbF",
        "outputId": "1d951f1b-31cb-4529-92c3-9dd698d163c5"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def sample(num_samples:int, model:torch.nn.Module, alpha:torch.Tensor, alpha_bar:torch.Tensor, T:int=200, device:str='cpu') -> List[torch.Tensor]:\n",
        "    \"\"\"\n",
        "    Takes the model, the alphas and the number of timesteps and returns a list of the sampled data for each timestep\n",
        "    args:\n",
        "        model: the denoising model\n",
        "        alphas: the alphas of the noise schedule\n",
        "        T: the number of timesteps\n",
        "    returns:\n",
        "        x_series: a list of the sampled data for each timestep\n",
        "    \"\"\"\n",
        "    alpha = alpha.to(device)\n",
        "    alpha_bar = alpha_bar.to(device)\n",
        "    steps = []\n",
        "    xt = torch.randn((num_samples, 2)).to(device)\n",
        "    for t in reversed(range(T)):\n",
        "        t_batch = torch.full((num_samples,), t).to(device)\n",
        "        noise_pred = model(xt, t_batch)\n",
        "        mu_hat_t = (xt - (1-alpha[t,None])/(1-alpha_bar[t,None]).sqrt()*noise_pred)/(alpha[t,None]).sqrt()\n",
        "\n",
        "        z = torch.randn_like(xt).to(device)\n",
        "        sigma = (1.-alpha[t]).sqrt()\n",
        "        xt = mu_hat_t + sigma*z\n",
        "        steps.append(xt.clone().detach().to('cpu'))\n",
        "    return steps\n",
        "\n",
        "steps = sample(1000, model, alphas, alpha_bar, T=T, device=device)\n",
        "plt.figure(figsize=[6, 6])\n",
        "plt.scatter(steps[-1][:,0],steps[-1][:,1],s=15,alpha=0.5)\n",
        "plt.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "OK, nothing new here. It is exactly what we did in the previous practical session.  \n",
        "Here we have no onctrol on the class of data we are sampling.  \n",
        "If we had to do an analogy with images, we would be sampling from a dataset of images without any control on the class of the image we are sampling.  \n",
        "We would like to be able to sample from a specific class.  \n",
        "This is where conditional diffusion comes into play.  \n",
        "Define a conditional denoising model, that takes as input the data the timestep and the class and outputs the predicted noise.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ConditionalDenoisier(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        ...\n",
        "    def forward(self, x, y, t):\n",
        "        ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now implement a conditional training loop.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def conditional_train(model, train_dataloader, optimizer, alpha_bar, epochs=50, device='cpu'):\n",
        "    progress_bar = tqdm(range(epochs), desc=\"Training\")\n",
        "    for epoch in range(epochs):\n",
        "        ...\n",
        "\n",
        "        progress_bar.set_postfix({\"epoch\": epoch, \"loss\": total_loss/x.shape[0]})\n",
        "        progress_bar.update()\n",
        "    progress_bar.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And train your conditional denoising model.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = ConditionalDenoisier().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We also have to modify the sampling function to be able to sample from a specific class.  \n",
        "Implement the following function.  and generate 1000 samples from the class 0.  \n",
        "To better visualize the results, you can plot the samples in green and the original data in blue.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def conditional_sample(num_samples:int, model:torch.nn.Module, label:int, alpha:torch.Tensor, alpha_bar:torch.Tensor, T:int=200, device:str='cpu') -> List[torch.Tensor]:\n",
        "    \"\"\"\n",
        "    Takes the model, the alphas and the number of timesteps and returns a list of the sampled data for each timestep\n",
        "    args:\n",
        "        model: the denoising model\n",
        "        alphas: the alphas of the noise schedule\n",
        "        T: the number of timesteps\n",
        "    returns:\n",
        "        x_series: a list of the sampled data for each timestep\n",
        "    \"\"\"\n",
        "    ...\n",
        "\n",
        "steps = conditional_sample(1000, model, 0, alphas, alpha_bar, T=T, device=device)\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Verify that your model can also sample from the other class.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You should now have a model that can sample from a specific class.  \n",
        "Even if it is not the case with our small dataset, saampling with diffusion model is a slow process.  \n",
        "A naiv solution would be to skip some timesteps.  \n",
        "Implement the following function to sample from a subset of timesteps (50 instead of 200 for instance) and check how it affects the quality of the samples.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def skip_step_samples(num_samples: int, model: torch.nn.Module, label: int, alpha: torch.Tensor, alpha_bar: torch.Tensor, T: int=200, num_steps: int=50, device: str='cpu') -> List[torch.Tensor]:\n",
        "    \"\"\"\n",
        "    Takes the model, the alphas and samples at a subset of timesteps\n",
        "    args:\n",
        "        model: the denoising model\n",
        "        alpha: noise schedule alphas\n",
        "        alpha_bar: cumulative product of alphas\n",
        "        T: total timesteps in noise schedule\n",
        "        num_steps: number of actual sampling steps to perform\n",
        "        device: device to run on\n",
        "    returns:\n",
        "        steps: list of sampled data at each sampled timestep\n",
        "    \"\"\"\n",
        "    ...\n",
        "\n",
        "steps = skip_step_samples(1000, model, 0, alphas, alpha_bar, T=T, num_steps=50, device=device)\n",
        "\n",
        "plt.figure(figsize=[6, 6])\n",
        "plt.scatter(steps[-1][:,0], steps[-1][:,1], s=15, alpha=0.5, c='g')\n",
        "plt.scatter(x_0[:,0], x_0[:,1], s=15, alpha=0.5, c=y)\n",
        "plt.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You should have observed a loss in quality when sampling from a subset of timesteps.  \n",
        "We saw in class that we could improve the quality of the samples by using a different sampling scheme.  \n",
        "Implement the following function to sample from a subset of timesteps using the DDIM sampling scheme from [this paper](https://arxiv.org/pdf/2010.02502) and check how it affects the quality of the samples.  \n",
        "![](images/ddim.png)  \n",
        "You can even try with 20 steps instead of 50.  and see the quality of the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def DDIM_sample_ddim(num_samples: int, model: torch.nn.Module, label: int, alpha: torch.Tensor, alpha_bar: torch.Tensor, T: int=200, num_steps: int=20, device: str='cpu') -> List[torch.Tensor]:\n",
        "    \"\"\"\n",
        "    DDIM sampling at subset of timesteps\n",
        "    args:\n",
        "        model: the denoising model\n",
        "        alpha: noise schedule alphas\n",
        "        alpha_bar: cumulative product of alphas\n",
        "        T: total timesteps in noise schedule\n",
        "        num_steps: number of actual sampling steps to perform\n",
        "        device: device to run on\n",
        "    returns:\n",
        "        steps: list of sampled data at each sampled timestep\n",
        "    \"\"\"\n",
        "   ...\n",
        "    \n",
        "    return steps\n",
        "\n",
        "steps = DDIM_sample_ddim(1000, model, 0, alphas, alpha_bar, T=T, num_steps=50, device=device)\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pretty fast and still accurate right!\n",
        "That's it for the 2d data, in the rest of the practical session we will work on images.  "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02aeb15c28914b9f9ea0ce0fe8126101": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28a99c22e63f4222979799356da5363e",
            "max": 3000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0584c8119c5547e498223b3f3fe1b86e",
            "value": 3000
          }
        },
        "043d01bcd99641fda43e813ba2efe7e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0584c8119c5547e498223b3f3fe1b86e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "247ba8c2ecfa44eba4e1f7bf6cdb6de4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a8652cf0f50a4dd2944b6c00589b53cf",
              "IPY_MODEL_02aeb15c28914b9f9ea0ce0fe8126101",
              "IPY_MODEL_a7840a61b55d4da4baace57bdade9e4a"
            ],
            "layout": "IPY_MODEL_8c7bfb6885b54e208a2660833ae14113"
          }
        },
        "28a99c22e63f4222979799356da5363e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b36902929ce4e5b8f9eddf96befe381": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b977a780d6b47a691699be9254c576c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fef32e50cebd439995b6dd3213e62da4",
            "placeholder": "​",
            "style": "IPY_MODEL_9306690fc9a6405b85be4fc0b86b85db",
            "value": " 3000/3000 [01:27&lt;00:00, 38.83it/s, epoch=2999, loss=2.05]"
          }
        },
        "44ff2d36b1ac4dd2b699d91df263c925": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5df7af6dc686422bbde6a1366d37b4f1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a97e77fb5cd4b4aae8ead106ea700c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa5f340489b94fb8acbdbf7ef874e571",
            "max": 3000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_971de86e5d6f4f30827ea8e66ab3dcf2",
            "value": 3000
          }
        },
        "8c7bfb6885b54e208a2660833ae14113": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9306690fc9a6405b85be4fc0b86b85db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "971de86e5d6f4f30827ea8e66ab3dcf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a7840a61b55d4da4baace57bdade9e4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f52e80b428ce40f3b5dc633b73750803",
            "placeholder": "​",
            "style": "IPY_MODEL_d09e519aeb1c475da96550a03a9dbdd5",
            "value": " 3000/3000 [01:20&lt;00:00, 41.90it/s, epoch=2999, loss=2.15]"
          }
        },
        "a8652cf0f50a4dd2944b6c00589b53cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3ed871edad94604ac0cb796128439ef",
            "placeholder": "​",
            "style": "IPY_MODEL_2b36902929ce4e5b8f9eddf96befe381",
            "value": "Training: 100%"
          }
        },
        "b3ed871edad94604ac0cb796128439ef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d09e519aeb1c475da96550a03a9dbdd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e28e0b941950447a98da71efeff9f1c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5df7af6dc686422bbde6a1366d37b4f1",
            "placeholder": "​",
            "style": "IPY_MODEL_043d01bcd99641fda43e813ba2efe7e8",
            "value": "Training: 100%"
          }
        },
        "f52e80b428ce40f3b5dc633b73750803": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa5f340489b94fb8acbdbf7ef874e571": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fef32e50cebd439995b6dd3213e62da4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff0ec0705d0b4b899c27405e49777904": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e28e0b941950447a98da71efeff9f1c2",
              "IPY_MODEL_8a97e77fb5cd4b4aae8ead106ea700c6",
              "IPY_MODEL_2b977a780d6b47a691699be9254c576c"
            ],
            "layout": "IPY_MODEL_44ff2d36b1ac4dd2b699d91df263c925"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
